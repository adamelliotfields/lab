{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoders\n",
    "\n",
    "[![Open in Colab](https://lab.aef.me/files/assets/colab-badge.svg)](https://colab.research.google.com/github/adamelliotfields/lab/blob/main/files/tf/vae.ipynb)\n",
    "[![Open in Kaggle](https://lab.aef.me/files/assets/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/adamelliotfields/lab/blob/main/files/tf/vae.ipynb)\n",
    "[![Render nbviewer](https://lab.aef.me/files/assets/nbviewer_badge.svg)](https://nbviewer.org/github/adamelliotfields/lab/blob/main/files/tf/vae.ipynb)\n",
    "[![W&B](https://img.shields.io/badge/Weights_&_Biases-FFCC33?logo=WeightsAndBiases&logoColor=black)](https://wandb.ai/adamelliotfields/vae-mnist)\n",
    "\n",
    "This notebook includes implementations of fully-connected and convolutional variational autoencoders (VAEs) using TensorFlow and Keras, trained on MNIST. We'll use the [trainer pattern](https://keras.io/examples/keras_recipes/trainer_pattern/) to override the VAE's `train_step` method to implement a custom loss function in the training loop. We'll then sample points from the latent space at a regular interval and feed them through the decoder to transform them into a grid of new images.\n",
    "\n",
    "![Latent digits](https://lab.aef.me/files/assets/vae_mlp_digits_v50.png)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "An [autoencoder](https://en.wikipedia.org/wiki/Autoencoder) is a type of generative model that learns to encode data into a _latent space_ representation and then decode it back to the original space. The primary goal of an autoencoder is to learn an efficient representation (encoding) of the data.\n",
    "\n",
    "In statistics, latent or \"hidden\" variables are ones that can only be inferred indirectly by modeling observed (visible) data. In the context of autoencoders, the latent space is a lower-dimensional representation of the data that captures the most important features.\n",
    "\n",
    "A [variational autoencoder](https://en.wikipedia.org/wiki/Variational_autoencoder) (VAE) is an extension of the autoencoder that learns to model a probability distribution over the latent space. This approach allows the VAE to generate new data by sampling from the learned distribution. VAEs are a type of generative model, also known as a _latent variable model_, that can generate new data samples similar to the training data.\n",
    "\n",
    "## Bayes Theorem\n",
    "\n",
    "To understand VAEs, it's important to grasp some key concepts from probability theory.\n",
    "\n",
    "[Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) is a cornerstone of [probability theory](https://en.wikipedia.org/wiki/Probability_theory) and provides a way to update the probability of a hypothesis based on new observations. It is defined as:\n",
    "\n",
    "$p(z|x) = \\frac{p(x|z) \\cdot p(z)}{p(x)}$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $p(z|x)$ is the posterior probability: the probability of the latent variable $z$ given the observed data $x$\n",
    "* $p(x|z)$ is the likelihood: the probability of observing the data $x$ given the latent variable $z$\n",
    "* $p(z)$ is the prior probability: the initial belief about the latent variable $z$ before observing the data\n",
    "* $p(x)$ is the marginal likelihood: the total probability of observing the data $x$ under all possible values of $z$\n",
    "\n",
    "In a VAE, $z$ is a lower-dimensional representation of the data $x$.\n",
    "\n",
    "### Intractability of the Posterior\n",
    "\n",
    "The marginal likelihood $p(x)$ (the denominator) requires [integrating](https://en.wikipedia.org/wiki/Integral) over all possible values of the latent variable $z$. In most cases, it is infeasible to compute this integral directly, hence why it is said to be intractable. To address this, variational inference (VI) is used to approximate the true posterior distribution with a simpler, tractable distribution $q(z|x)$. The goal is to find the distribution $q(z|x)$ that is as close as possible to $p(z|x)$.\n",
    "\n",
    "To measure the difference between two probability distributions, the [Kullback-Leibler](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) (KL) divergence is used. However, directly minimizing the KL divergence is still a challenge because it depends on $p(z|x)$, which is intractable. Instead, VAEs optimize a different objective known as the Evidence Lower Bound (ELBO):\n",
    "\n",
    "$\\text{ELBO} = \\mathbb{E}_{q(z|x)}[\\log p(x|z)] - \\text{KL}[q(z|x) || p(z)]$\n",
    "\n",
    "The left term is the reconstruction loss, which measures how well the model reconstructs the input data. The right term is the KL divergence between the approximate posterior $q(z|x)$ and the prior $p(z)$. Thus, maximizing the ELBO is equivalent to minimizing the KL divergence between $q(z|x)$ and $p(z|x)$.\n",
    "\n",
    "In practice, the encoder neural network approximates the posterior $q(z|x)$, and the decoder models the likelihood $p(x|z)$. The encoder net maps the input data $x$ to the parameters of $q(z|x)$, while the decoder net reconstructs $x$ from the latent space $z$. During training, both networks are optimized simultaneously to maximize the ELBO.\n",
    "\n",
    "## Reparameterization Trick\n",
    "\n",
    "In traditional neural networks using gradient descent, the weights are updated directly based on the gradients of the loss function. This relies on the _deterministic_ nature of the network's operations to compute the gradients. In a VAE, the encoder outputs the parameters of the distribution $q(z|x)$, which are then used to sample a latent variable $z$. This sampling operation is _stochastic_, introducing randomness which makes it impossible to compute the gradients.\n",
    "\n",
    "To address this issue, the _reparameterization trick_ is used to express the random variable $z$ as a deterministic function of the input data $x$ and some additional random noise $\\epsilon$. In practice, the encoder outputs the mean $\\mu$ and the logarithm of the variance $\\log \\sigma^2$ of $q(z|x)$.\n",
    "\n",
    "Instead of sampling $z$ directly from this distribution, we sample $\\epsilon$ from a standard normal distribution $\\mathcal{N}(0, I)$ (mean of `0` and standard deviation of `1`). Then, $z$ is computed as:\n",
    "\n",
    "$z = \\mu + \\sigma \\cdot \\epsilon$\n",
    "\n",
    "Here, $\\sigma$ is obtained by taking the exponential of $\\frac{1}{2} \\log(\\sigma^2)$ to ensure that $z$ is a differentiable function of $\\mu$, $\\sigma$, and $\\epsilon$ allowing the model's parameters to be learned using standard backpropagation methods. In code, it looks like this:\n",
    "\n",
    "```py\n",
    "from keras import losses, ops\n",
    "\n",
    "z_mean, z_log_var, z = encoder(data)\n",
    "reconstruction = decoder(z)\n",
    "\n",
    "reconstruction_loss = losses.binary_crossentropy(data, reconstruction)\n",
    "reconstruction_loss = ops.mean(ops.sum(reconstruction_loss, axis=(1, 2)))\n",
    "\n",
    "kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
    "kl_loss = ops.mean(ops.sum(kl_loss, axis=1))\n",
    "\n",
    "total_loss = reconstruction_loss + kl_loss\n",
    "```\n",
    "\n",
    "## Resources\n",
    "\n",
    "https://github.com/lyeoni/pytorch-mnist-VAE\n",
    "\n",
    "https://github.com/rcantini/CNN-VAE-MNIST\n",
    "\n",
    "https://www.tensorflow.org/tutorials/generative/cvae\n",
    "\n",
    "https://keras.io/examples/generative/vae\n",
    "\n",
    "https://keras.io/examples/keras_recipes/trainer_pattern\n",
    "\n",
    "[Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114) (Kingma & Welling, 2013)\n",
    "\n",
    "[Tutorial on Variational Autoencoders](https://arxiv.org/abs/1606.05908) (Doersch, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "\n",
    "    subprocess.run([\"pip\", \"install\", \"-qU\", \"keras\", \"wandb\"])\n",
    "    os.environ[\"WANDB_DISABLE_GIT\"] = \"true\"\n",
    "    os.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")\n",
    "    os.environ[\"TFDS_DATA_DIR\"] = \"/content/drive/MyDrive/tensorflow_datasets\"\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "assert os.environ.get(\"WANDB_API_KEY\"), \"missing WANDB_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "\n",
    "from keras import (\n",
    "    Input,\n",
    "    Model,\n",
    "    backend,\n",
    "    callbacks,\n",
    "    layers,\n",
    "    losses,\n",
    "    metrics,\n",
    "    ops,\n",
    "    optimizers,\n",
    "    random,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42  # @param {type:\"integer\"}\n",
    "EPOCHS = 50  # @param {type:\"integer\"}\n",
    "VERBOSE = 1  # @param {type:\"integer\"}\n",
    "LATENT_DIM = 2  # @param {type:\"integer\"}\n",
    "BATCH_SIZE = 128  # @param {type:\"integer\"}\n",
    "ACTIVATION = \"gelu\"  # @param [\"relu\", \"leaky_relu\", \"swish\", \"gelu\"] {type:\"string\"}\n",
    "WEIGHT_DECAY = 0.004  # @param {type:\"number\"}\n",
    "LEARNING_RATE = 0.001  # @param {type:\"number\"}\n",
    "\n",
    "WANDB_PROJECT = \"vae-mnist\"  # @param {type:\"string\"}\n",
    "WANDB_ENTITY = \"adamelliotfields\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Functions\n",
    "def get_latent_digits(decoder, n=20):\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((28 * n, 28 * n))\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    # iterate over the grid\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample, verbose=0)\n",
    "            digit = x_decoded[0].reshape(28, 28)\n",
    "            figure[\n",
    "                i * 28 : (i + 1) * 28,\n",
    "                j * 28 : (j + 1) * 28,\n",
    "            ] = digit\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_train, mnist_test), mnist_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    split=[\"train\", \"test\"],\n",
    ")\n",
    "X_train = (\n",
    "    mnist_train.concatenate(mnist_test)\n",
    "    .map(lambda X, y: (tf.cast(X, tf.float32) / 255.0, y))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_batch, _ in X_train.take(1):\n",
    "    for index in range(12):\n",
    "        plt.subplot(3, 4, index + 1)\n",
    "        plt.imshow(\n",
    "            # index, height, width, channels[0]\n",
    "            X_batch[index, :, :, 0],\n",
    "            cmap=\"binary\",\n",
    "        )\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling layer\n",
    "class MLPSampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def __init__(self, name=\"MLPSampling\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = name\n",
    "        self.seed_generator = random.SeedGenerator(SEED)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = ops.shape(z_mean)[0]\n",
    "        dim = ops.shape(z_mean)[1]\n",
    "        epsilon = random.normal(shape=(batch, dim), seed=self.seed_generator)\n",
    "        return z_mean + ops.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "# encoder\n",
    "def get_encoder_mlp(name=\"MLPEncoder\"):\n",
    "    inputs = Input(shape=(28, 28, 1))\n",
    "    x = layers.Flatten()(inputs)\n",
    "    x = layers.Dense(512, activation=ACTIVATION)(x)\n",
    "    x = layers.Dense(256, activation=ACTIVATION)(x)\n",
    "    z_mean = layers.Dense(LATENT_DIM)(x)\n",
    "    z_log_var = layers.Dense(LATENT_DIM)(x)\n",
    "    z = MLPSampling()([z_mean, z_log_var])\n",
    "    return Model(inputs, [z_mean, z_log_var, z], name=name)\n",
    "\n",
    "\n",
    "# decoder\n",
    "def get_decoder_mlp(name=\"MLPDecoder\"):\n",
    "    inputs = Input(shape=(LATENT_DIM,))\n",
    "    x = layers.Dense(256, activation=ACTIVATION)(inputs)\n",
    "    x = layers.Dense(512, activation=ACTIVATION)(x)\n",
    "    x = layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
    "    outputs = layers.Reshape((28, 28, 1))(x)\n",
    "    return Model(inputs, outputs, name=name)\n",
    "\n",
    "\n",
    "# models\n",
    "encoder_mlp = get_encoder_mlp()\n",
    "decoder_mlp = get_decoder_mlp()\n",
    "\n",
    "\n",
    "# VAE\n",
    "class VAE_MLP(Model):\n",
    "    def __init__(self, encoder, decoder, name=\"VAE_MLP\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = name\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss = metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss = metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss = metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss, self.reconstruction_loss, self.kl_loss]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = losses.binary_crossentropy(data, reconstruction)\n",
    "            reconstruction_loss = ops.mean(ops.sum(reconstruction_loss, axis=(1, 2)))\n",
    "            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
    "            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss.update_state(total_loss)\n",
    "        self.reconstruction_loss.update_state(reconstruction_loss)\n",
    "        self.kl_loss.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss.result(),\n",
    "            \"kl_loss\": self.kl_loss.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "backend.clear_session()\n",
    "vae_mlp = VAE_MLP(encoder_mlp, decoder_mlp)\n",
    "vae_mlp.compile(optimizer=optimizers.AdamW(weight_decay=WEIGHT_DECAY, learning_rate=LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(\n",
    "    tags=[\"L4\"],\n",
    "    group=\"mlp\",\n",
    "    job_type=\"train\",\n",
    "    entity=WANDB_ENTITY,\n",
    "    project=WANDB_PROJECT,\n",
    "    config={\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"model\": \"MLP_VAE\",\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"activation\": ACTIVATION,\n",
    "        \"weight_decay\": WEIGHT_DECAY,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "    },\n",
    ") as run:\n",
    "    vae_mlp.fit(\n",
    "        X_train.map(lambda X, _: X),\n",
    "        epochs=EPOCHS,\n",
    "        verbose=VERBOSE,\n",
    "        callbacks=[\n",
    "            callbacks.ReduceLROnPlateau(mode=\"min\", patience=5, monitor=\"reconstruction_loss\"),\n",
    "            callbacks.EarlyStopping(mode=\"min\", patience=10, monitor=\"reconstruction_loss\"),\n",
    "            WandbMetricsLogger(log_freq=\"epoch\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    fig = get_latent_digits(decoder_mlp, n=20)\n",
    "    img = PILImage.fromarray(np.uint8(fig * 255))\n",
    "    img.save(\"latent_digits.png\")\n",
    "    run.log({\"Latent Digits\": wandb.Image(\"latent_digits.png\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNSampling(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.seed_generator = random.SeedGenerator(SEED)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = ops.shape(z_mean)[0]\n",
    "        dim = ops.shape(z_mean)[1]\n",
    "        epsilon = random.normal(shape=(batch, dim), seed=self.seed_generator)\n",
    "        return z_mean + ops.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def get_encoder_cnn(name=\"CNNEncoder\"):\n",
    "    inputs = Input(shape=(28, 28, 1))\n",
    "    x = layers.Conv2D(32, 3, activation=ACTIVATION, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.Conv2D(64, 3, activation=ACTIVATION, strides=2, padding=\"same\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(16, activation=ACTIVATION)(x)\n",
    "    z_mean = layers.Dense(LATENT_DIM)(x)\n",
    "    z_log_var = layers.Dense(LATENT_DIM)(x)\n",
    "    z = CNNSampling()([z_mean, z_log_var])\n",
    "    return Model(inputs, [z_mean, z_log_var, z], name=name)\n",
    "\n",
    "\n",
    "# decoder\n",
    "def get_decoder_cnn(name=\"CNNDecoder\"):\n",
    "    inputs = Input(shape=(LATENT_DIM,))\n",
    "    x = layers.Dense(7 * 7 * 64, activation=ACTIVATION)(inputs)\n",
    "    x = layers.Reshape((7, 7, 64))(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, activation=ACTIVATION, strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2DTranspose(32, 3, activation=ACTIVATION, strides=2, padding=\"same\")(x)\n",
    "    outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "    return Model(inputs, outputs, name=name)\n",
    "\n",
    "\n",
    "# models\n",
    "encoder_cnn = get_encoder_cnn()\n",
    "decoder_cnn = get_decoder_cnn()\n",
    "\n",
    "\n",
    "# VAE\n",
    "class VAE_CNN(Model):\n",
    "    def __init__(self, encoder, decoder, name=\"VAE_CNN\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = name\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss = metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss = metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss = metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss, self.reconstruction_loss, self.kl_loss]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = losses.binary_crossentropy(data, reconstruction)\n",
    "            reconstruction_loss = ops.mean(ops.sum(reconstruction_loss, axis=(1, 2)))\n",
    "            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
    "            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss.update_state(total_loss)\n",
    "        self.reconstruction_loss.update_state(reconstruction_loss)\n",
    "        self.kl_loss.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss.result(),\n",
    "            \"kl_loss\": self.kl_loss.result(),\n",
    "        }\n",
    "\n",
    "\n",
    "backend.clear_session()\n",
    "vae_cnn = VAE_CNN(encoder_cnn, decoder_cnn)\n",
    "vae_cnn.compile(optimizer=optimizers.AdamW(weight_decay=WEIGHT_DECAY, learning_rate=LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(\n",
    "    tags=[\"L4\"],\n",
    "    group=\"cnn\",\n",
    "    job_type=\"train\",\n",
    "    entity=WANDB_ENTITY,\n",
    "    project=WANDB_PROJECT,\n",
    "    config={\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"model\": \"CNN_VAE\",\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"activation\": ACTIVATION,\n",
    "        \"weight_decay\": WEIGHT_DECAY,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "    },\n",
    ") as run:\n",
    "    vae_cnn.fit(\n",
    "        X_train.map(lambda X, _: X),\n",
    "        epochs=EPOCHS,\n",
    "        verbose=VERBOSE,\n",
    "        callbacks=[\n",
    "            callbacks.ReduceLROnPlateau(mode=\"min\", patience=5, monitor=\"reconstruction_loss\"),\n",
    "            callbacks.EarlyStopping(mode=\"min\", patience=10, monitor=\"reconstruction_loss\"),\n",
    "            WandbMetricsLogger(log_freq=\"epoch\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    fig = get_latent_digits(decoder_cnn, n=20)\n",
    "    img = PILImage.fromarray(np.uint8(fig * 255))\n",
    "    img.save(\"latent_digits_cnn.png\")\n",
    "    run.log({\"Latent Digits (CNN)\": wandb.Image(\"latent_digits_cnn.png\")})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
