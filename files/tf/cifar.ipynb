{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR (TensorFlow)\n",
    "\n",
    "[![Open in Colab](https://lab.aef.me/files/assets/colab-badge.svg)](https://colab.research.google.com/github/adamelliotfields/lab/blob/main/files/tf/cifar.ipynb)\n",
    "[![Open in Kaggle](https://lab.aef.me/files/assets/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/adamelliotfields/lab/blob/main/files/tf/cifar.ipynb)\n",
    "[![Render nbviewer](https://lab.aef.me/files/assets/nbviewer_badge.svg)](https://nbviewer.org/github/adamelliotfields/lab/blob/main/files/tf/cifar.ipynb)\n",
    "\n",
    "In 2006, researchers from MIT CSAIL created the [Tiny Images](https://people.csail.mit.edu/billf/papers/80millionImages.pdf) dataset. They used over 50,000 nouns from [WordNet](https://en.wikipedia.org/wiki/WordNet) to search for images on the web and subsequently label them, resulting in 80 million 32x32 images. Unfortunately, due to the automated nature of the search, many [inappropriate](https://openreview.net/pdf?id=s-e2zaAlG3I) words and images ended up in the dataset. The dataset was taken down in [2020](https://groups.csail.mit.edu/vision/TinyImages/).\n",
    "\n",
    "[CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html) are labeled subsets of the Tiny Images dataset. Each dataset has 60,000 32x32 color images, with 10,000 reserved for testing. CIFAR-10 has 10 classes, while CIFAR-100 has 100. It was introduced in [Learning Multiple Layers of Features from Tiny Images](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf) (Krizhevsky, 2009).\n",
    "\n",
    "This notebook will be about _transfer learning_, so we'll start with a model trained on ImageNet, remove the top layer, freeze the weights, and train a new layer on CIFAR-10. The image data is fed through the base model and the extracted features are passed to the new layer for learning.\n",
    "\n",
    "Once training has converged, we'll unfreeze all of the layers and retrain at a much lower learning rate for a few additional epochs. This is _fine-tuning_.\n",
    "\n",
    "Read the [Keras guide](https://keras.io/guides/transfer_learning/) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from importlib.util import find_spec\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "if find_spec(\"google.colab\") is not None:\n",
    "    os.environ[\"TFDS_DATA_DIR\"] = \"/content/drive/MyDrive/tensorflow_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from keras import Input, Model, Sequential, applications, callbacks, layers, losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi --query-gpu=name,memory.total,memory.used,memory.free,utilization.gpu,utilization.memory --format=csv\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Config\n",
    "SEED = 42  # @param {type:\"integer\"}\n",
    "EPOCHS = 15  # @param {type:\"integer\"}\n",
    "VERBOSE = 1  # @param {type:\"integer\"}\n",
    "CLASSES = 10  # @param {type:\"integer\"}\n",
    "IMAGE_SIZE = 75  # @param {type:\"integer\"}\n",
    "BATCH_SIZE = 128  # @param {type:\"integer\"}\n",
    "VAL_SIZE = 5000  # @param {type:\"integer\"}\n",
    "TEST_SIZE = 10000  # @param {type:\"integer\"}\n",
    "TRAIN_SIZE = 45000  # @param {type:\"integer\"}\n",
    "LEARNING_RATE = 0.001  # @param {type:\"number\"}\n",
    "WEIGHT_DECAY = 0.004  # @param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Lib\n",
    "def show_cifar_images(\n",
    "    ds,\n",
    "    *,\n",
    "    rows=1,\n",
    "    size=2,\n",
    "    columns=5,\n",
    "    figsize=None,\n",
    "    label_decoder=None,\n",
    "):\n",
    "    if figsize is None:\n",
    "        figsize = (columns * size, rows * size)\n",
    "\n",
    "    _, axes = plt.subplots(rows, columns, figsize=figsize)\n",
    "\n",
    "    for i, (image, label) in enumerate(ds.take(rows * columns)):\n",
    "        image = image.numpy().squeeze()\n",
    "\n",
    "        # rescale from -1, 1 to 0, 1\n",
    "        if image.min() < 0:\n",
    "            image = (image + 1) / 2\n",
    "\n",
    "        # rescale to 0, 255 integers\n",
    "        if not image.max() > 1:\n",
    "            image = image * 255\n",
    "\n",
    "        image = image.astype(\"uint8\")\n",
    "\n",
    "        ax = axes[i // columns, i % columns] if rows > 1 else axes[i]\n",
    "        ax.imshow(image)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # if one-hot encoded\n",
    "        label = tf.squeeze(label)\n",
    "        if tf.rank(label) > 0:\n",
    "            label = tf.argmax(label)\n",
    "\n",
    "        if label_decoder is not None:\n",
    "            ax.set_title(label_decoder(label))\n",
    "        else:\n",
    "            ax.set_title(f\"{label}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def prepare_cifar_image(image, label):\n",
    "    label = tf.one_hot(label, CLASSES)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "def decode_cifar_label(label):\n",
    "    # fmt: off\n",
    "    labels_10 = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "    labels_100 = [\n",
    "        \"apple\", \"aquarium_fish\", \"baby\", \"bear\", \"beaver\", \"bed\", \"bee\", \"beetle\", \"bicycle\", \"bottle\",\n",
    "        \"bowl\", \"boy\", \"bridge\", \"bus\", \"butterfly\", \"camel\", \"can\", \"castle\", \"caterpillar\", \"cattle\",\n",
    "        \"chair\", \"chimpanzee\", \"clock\", \"cloud\", \"cockroach\", \"couch\", \"crab\", \"crocodile\", \"cup\",\n",
    "        \"dinosaur\", \"dolphin\", \"elephant\", \"flatfish\", \"forest\", \"fox\", \"girl\", \"hamster\", \"house\",\n",
    "        \"kangaroo\", \"computer_keyboard\", \"lamp\", \"lawn_mower\", \"leopard\", \"lion\", \"lizard\", \"lobster\",\n",
    "        \"man\", \"maple_tree\", \"motorcycle\", \"mountain\", \"mouse\", \"mushroom\", \"oak_tree\", \"orange\",\n",
    "        \"orchid\", \"otter\", \"palm_tree\", \"pear\", \"pickup_truck\", \"pine_tree\", \"plain\", \"plate\", \"poppy\",\n",
    "        \"porcupine\", \"possum\", \"rabbit\", \"raccoon\", \"ray\", \"road\", \"rocket\", \"rose\", \"sea\", \"seal\",\n",
    "        \"shark\", \"shrew\", \"skunk\", \"skyscraper\", \"snail\", \"snake\", \"spider\", \"squirrel\", \"streetcar\",\n",
    "        \"sunflower\", \"sweet_pepper\", \"table\", \"tank\", \"telephone\", \"television\", \"tiger\", \"tractor\",\n",
    "        \"train\", \"trout\", \"tulip\", \"turtle\", \"wardrobe\", \"whale\", \"willow_tree\", \"wolf\", \"woman\", \"worm\"\n",
    "    ]\n",
    "    # fmt: on\n",
    "    labels = labels_100 if CLASSES == 100 else labels_10\n",
    "    return f\"{labels[label]} ({label})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Data\n",
    "(cifar_train, cifar_test), cifar_info = tfds.load(\n",
    "    \"cifar100\" if CLASSES == 100 else \"cifar10\",\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    split=[\"train\", \"test\"],\n",
    ")\n",
    "\n",
    "# fmt: off\n",
    "X_train, X_val, X_test = (\n",
    "    cifar_train.take(TRAIN_SIZE).map(prepare_cifar_image).shuffle(seed=SEED, buffer_size=cifar_train.cardinality()).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE),\n",
    "    cifar_train.skip(TRAIN_SIZE).take(VAL_SIZE).map(prepare_cifar_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE),\n",
    "    cifar_test.take(TEST_SIZE).map(prepare_cifar_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE),\n",
    ")\n",
    "# fmt: on\n",
    "\n",
    "show_cifar_images(\n",
    "    cifar_train,\n",
    "    rows=2,\n",
    "    label_decoder=decode_cifar_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = Sequential(\n",
    "    [\n",
    "        # random augments aren't applied during inferencing, but the resizing and rescaling layers are\n",
    "        layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        layers.RandomFlip(mode=\"horizontal\", seed=SEED),\n",
    "        layers.RandomTranslation(\n",
    "            height_factor=0.1,\n",
    "            width_factor=0.1,\n",
    "            fill_mode=\"constant\",\n",
    "            fill_value=0,\n",
    "            seed=SEED,\n",
    "        ),\n",
    "        layers.Rescaling(scale=2.0 / 255, offset=-1.0),  # from 0,255 to -1,1\n",
    "    ],\n",
    "    name=\"augment\",\n",
    ")\n",
    "\n",
    "# keep separate from \"model\" so you can set trainable later\n",
    "# also try other models like Xception, InceptionV3, EfficientNetV2S, etc\n",
    "base = applications.ResNet50V2(\n",
    "    pooling=\"avg\",\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),  # channels-last\n",
    ")\n",
    "base.trainable = False\n",
    "\n",
    "# use original CIFAR size as input\n",
    "x_inputs = Input(shape=(32, 32, 3), name=\"input\")\n",
    "x = augment(x_inputs)\n",
    "x = base(x, training=False)  # set training to False so layers like batch norm are disabled\n",
    "x = layers.Dense(CLASSES, name=\"output\")(x)\n",
    "\n",
    "model = Model(inputs=x_inputs, outputs=x, name=f\"CIFAR-{CLASSES}\")\n",
    "model.compile(\n",
    "    metrics=[\"accuracy\"],\n",
    "    loss=losses.CategoricalCrossentropy(from_logits=True),  # no softmax so output is raw logits\n",
    "    optimizer=optimizers.AdamW(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_callback = callbacks.ReduceLROnPlateau(min_delta=0.001, patience=3, verbose=VERBOSE)\n",
    "ckpt_callback = callbacks.ModelCheckpoint(\n",
    "    # if you don't use tokens like \"{epoch}\" then the file gets overwritten\n",
    "    \"resnet-cifar10.model.keras\",\n",
    "    verbose=VERBOSE,\n",
    "    monitor=\"accuracy\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=VERBOSE,\n",
    "    validation_data=X_val,\n",
    "    callbacks=[lr_callback, ckpt_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze and recompile with lower learning rate\n",
    "base.trainable = True\n",
    "model.compile(\n",
    "    metrics=[\"accuracy\"],\n",
    "    loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=optimizers.AdamW(learning_rate=LEARNING_RATE / 100, weight_decay=WEIGHT_DECAY / 100),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_ft_callback = callbacks.ModelCheckpoint(\n",
    "    \"resnet-cifar10-ft.model.keras\",\n",
    "    verbose=VERBOSE,\n",
    "    monitor=\"accuracy\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    epochs=1,\n",
    "    verbose=VERBOSE,\n",
    "    validation_data=X_val,\n",
    "    callbacks=[ckpt_ft_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test data\n",
    "model.evaluate(X_test, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
